{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuL/NnAXo5hwWpydt7lOlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KiranEC11/LSTM/blob/main/LSTM_Next_n_character_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kZE8o9KtGWGV"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "T8aSgT0SGdFU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if a GPU is available\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"GPU available\")\n",
        "else:\n",
        "    print(\"GPU not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRQMBU_wXtqS",
        "outputId": "37e1ba06-502a-4007-82c2-ca2dade3c8d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-df6cb3a2ca13>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras import utils as np_utils"
      ],
      "metadata": {
        "id": "6Ygm7uKmGd7S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load txt file"
      ],
      "metadata": {
        "id": "Pm19PRZwIk92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filename = 'Macbeth.txt'\n",
        "# with open(filename, 'r') as f:\n",
        "#     lines = f.readlines()"
      ],
      "metadata": {
        "id": "nh2u8aPIGr9U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Macbeth.txt'\n",
        "text = (open(filename).read()).lower()"
      ],
      "metadata": {
        "id": "NvHQCxmvH1yL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "fJmPSfBgJAu2",
        "outputId": "46fb84c9-7a89-4a6d-bba8-eb147cf93d19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the tragedie of macbeth\\n\\nactus primus. scoena prima.\\n\\nthunder and lightning. enter three witches.\\n\\n  1. when shall we three meet againe?\\nin thunder, lightning, or in raine?\\n  2. when the hurley-burley's done,\\nwhen the battaile's lost, and wonne\\n\\n   3. that will be ere the set of sunne\\n\\n   1. where the place?\\n  2. vpon the heath\\n\\n   3. there to meet with macbeth\\n\\n   1. i come, gray-malkin\\n\\n   all. padock calls anon: faire is foule, and foule is faire,\\nhouer through the fogge and filthie ayre.\\n\\nexeunt.\\n\\n\\nscena secunda.\\n\\nalarum within. enter king, malcome, donalbaine, lenox, with\\nattendants, meeting a bleeding captaine.\\n\\n  king. what bloody man is that? he can report,\\nas seemeth by his plight, of the reuolt\\nthe newest state\\n\\n   mal. this is the serieant,\\nwho like a good and hardie souldier fought\\n'gainst my captiuitie: haile braue friend;\\nsay to the king, the knowledge of the broyle,\\nas thou didst leaue it\\n\\n   cap. doubtfull it stood,\\nas two spent swimmers, that doe cling together,\\nand ch\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing steps"
      ],
      "metadata": {
        "id": "jDsv1CX1Ipuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text  = text.replace('\\n','').replace('\\n','')"
      ],
      "metadata": {
        "id": "7RS481dtIXmk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mWOayljRIs_s",
        "outputId": "301b9a1c-4928-4ad3-daca-b87344c0c6a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the tragedie of macbethactus primus. scoena prima.thunder and lightning. enter three witches.  1. when shall we three meet againe?in thunder, lightning, or in raine?  2. when the hurley-burley's done,when the battaile's lost, and wonne   3. that will be ere the set of sunne   1. where the place?  2. vpon the heath   3. there to meet with macbeth   1. i come, gray-malkin   all. padock calls anon: faire is foule, and foule is faire,houer through the fogge and filthie ayre.exeunt.scena secunda.alarum within. enter king, malcome, donalbaine, lenox, withattendants, meeting a bleeding captaine.  king. what bloody man is that? he can report,as seemeth by his plight, of the reuoltthe newest state   mal. this is the serieant,who like a good and hardie souldier fought'gainst my captiuitie: haile braue friend;say to the king, the knowledge of the broyle,as thou didst leaue it   cap. doubtfull it stood,as two spent swimmers, that doe cling together,and choake their art: the mercilesse macdonwald(w\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vz8mXXKJD1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare train dataset"
      ],
      "metadata": {
        "id": "y4bISNTxJG4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store unique words\n",
        "unique_chars  = sorted(list(set(text)))"
      ],
      "metadata": {
        "id": "RC35UFiCJIwC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T8aPwmaJZGs",
        "outputId": "13ed42c2-0ee9-4939-e797-b83cf6a90791"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4LRRTBxJbrb",
        "outputId": "c3046ee7-4da1-43ae-caea-7583634145bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " '!',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DIyarkxJz1g"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## char to int map\n",
        "char_to_int = {}\n",
        "\n",
        "## int to char map\n",
        "int_to_char = {}\n",
        "\n",
        "## lets update both the above maps\n",
        "\n",
        "for i,char in enumerate(unique_chars):\n",
        "    char_to_int.update({char:i})\n",
        "    int_to_char.update({i:char})\n"
      ],
      "metadata": {
        "id": "mVvI29RJJdbT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int['a']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B6ApO2fKPyn",
        "outputId": "355f6d2e-02f3-4ba6-b2a0-1a7bc2b7a7b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char[17]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "npXkLqWDKRks",
        "outputId": "0ee5c9a3-298b-4736-a143-942f32cfe75a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "its done"
      ],
      "metadata": {
        "id": "iE0qzM--KXqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## now prepare the train dataset\n",
        "\"\"\"\n",
        "collect sequences and next labels.\n",
        "timesteps = 50\n",
        "\"\"\"\n",
        "timestep = 50\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(0, len(text)-timestep, 1):\n",
        "    sequence = text[i:i+timestep]\n",
        "\n",
        "    X.append([char_to_int[char] for char in sequence])\n",
        "    y.append(char_to_int[text[i+timestep]])"
      ],
      "metadata": {
        "id": "H4EZnPnfKUpU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X[0] , y[0]"
      ],
      "metadata": {
        "id": "_WVpt0C7LxO7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reshaping X"
      ],
      "metadata": {
        "id": "H8f9hpS-MMv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "X shape should be = [samples, timsteps, features]\n",
        "features = number of outputs --> one character means features =1\n",
        "\"\"\"\n",
        "\n",
        "## reshaping\n",
        "X_modified =  np.reshape(X, (len(X), timestep, 1))\n",
        "\n",
        "## normalising\n",
        "X_modified = X_modified/float(len(unique_chars))"
      ],
      "metadata": {
        "id": "cJwOVmceL2A7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##y one hot encoding\n",
        "y_modified = np_utils.to_categorical(y)"
      ],
      "metadata": {
        "id": "rSIhUTj0NkuE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_modified[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWFLHWl3Nr90",
        "outputId": "b20c4692-48cb-432e-93ab-cbdbe0f55715"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "03Bhh0faOFC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM architecture"
      ],
      "metadata": {
        "id": "oyzPAOqtOSTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(300, input_shape = (X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(300))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y_modified.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam')\n",
        "\n"
      ],
      "metadata": {
        "id": "Jlts_1O_OUXc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acJZb7XwPd60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fitting the model and generating characters"
      ],
      "metadata": {
        "id": "cN_IbVOqPib7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_modified, y_modified, epochs = 100, batch_size = 30, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OKM80AiPlGH",
        "outputId": "3f814c94-d0dc-48fd-97e6-acb3975a27c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 2.6610\n",
            "Epoch 2/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.5007\n",
            "Epoch 3/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.3685\n",
            "Epoch 4/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 2.2635\n",
            "Epoch 5/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 2.1780\n",
            "Epoch 6/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.1114\n",
            "Epoch 7/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 2.0394\n",
            "Epoch 8/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.9802\n",
            "Epoch 9/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.9281\n",
            "Epoch 10/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.8785\n",
            "Epoch 11/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.8252\n",
            "Epoch 12/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.7819\n",
            "Epoch 13/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.7387\n",
            "Epoch 14/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.7000\n",
            "Epoch 15/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.6639\n",
            "Epoch 16/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.6306\n",
            "Epoch 17/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.5973\n",
            "Epoch 18/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.5673\n",
            "Epoch 19/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.5453\n",
            "Epoch 20/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.5154\n",
            "Epoch 21/100\n",
            "3233/3233 [==============================] - 34s 10ms/step - loss: 1.4903\n",
            "Epoch 22/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.4704\n",
            "Epoch 23/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.4501\n",
            "Epoch 24/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.4345\n",
            "Epoch 25/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.4202\n",
            "Epoch 26/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3986\n",
            "Epoch 27/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3908\n",
            "Epoch 28/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3779\n",
            "Epoch 29/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3692\n",
            "Epoch 30/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3507\n",
            "Epoch 31/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3482\n",
            "Epoch 32/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3357\n",
            "Epoch 33/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3322\n",
            "Epoch 34/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3254\n",
            "Epoch 35/100\n",
            "3233/3233 [==============================] - 35s 11ms/step - loss: 1.3147\n",
            "Epoch 36/100\n",
            "3233/3233 [==============================] - 34s 10ms/step - loss: 1.3155\n",
            "Epoch 37/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3077\n",
            "Epoch 38/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3083\n",
            "Epoch 39/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3064\n",
            "Epoch 40/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2920\n",
            "Epoch 41/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2914\n",
            "Epoch 42/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2950\n",
            "Epoch 43/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2957\n",
            "Epoch 44/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2882\n",
            "Epoch 45/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2866\n",
            "Epoch 46/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2881\n",
            "Epoch 47/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2835\n",
            "Epoch 48/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2893\n",
            "Epoch 49/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.3059\n",
            "Epoch 50/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2825\n",
            "Epoch 51/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2895\n",
            "Epoch 52/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2897\n",
            "Epoch 53/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2783\n",
            "Epoch 54/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2900\n",
            "Epoch 55/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2860\n",
            "Epoch 56/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2797\n",
            "Epoch 57/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2864\n",
            "Epoch 58/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2911\n",
            "Epoch 59/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2865\n",
            "Epoch 60/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2934\n",
            "Epoch 61/100\n",
            "3233/3233 [==============================] - 32s 10ms/step - loss: 1.2938\n",
            "Epoch 62/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2926\n",
            "Epoch 63/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2990\n",
            "Epoch 64/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2989\n",
            "Epoch 65/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3001\n",
            "Epoch 66/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.7263\n",
            "Epoch 67/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.5528\n",
            "Epoch 68/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.9738\n",
            "Epoch 69/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.7038\n",
            "Epoch 70/100\n",
            "3233/3233 [==============================] - 34s 10ms/step - loss: 1.5863\n",
            "Epoch 71/100\n",
            "3233/3233 [==============================] - 34s 10ms/step - loss: 1.4651\n",
            "Epoch 72/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3888\n",
            "Epoch 73/100\n",
            "3233/3233 [==============================] - 34s 10ms/step - loss: 1.3514\n",
            "Epoch 74/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3423\n",
            "Epoch 75/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3206\n",
            "Epoch 76/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3142\n",
            "Epoch 77/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3125\n",
            "Epoch 78/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3011\n",
            "Epoch 79/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3026\n",
            "Epoch 80/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3044\n",
            "Epoch 81/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2999\n",
            "Epoch 82/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3006\n",
            "Epoch 83/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2973\n",
            "Epoch 84/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2915\n",
            "Epoch 85/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2866\n",
            "Epoch 86/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.2987\n",
            "Epoch 87/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3065\n",
            "Epoch 88/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3090\n",
            "Epoch 89/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3148\n",
            "Epoch 90/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3050\n",
            "Epoch 91/100\n",
            "3233/3233 [==============================] - 34s 11ms/step - loss: 1.3176\n",
            "Epoch 92/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 1.3134\n",
            "Epoch 93/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 3.2348\n",
            "Epoch 94/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.8443\n",
            "Epoch 95/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.6950\n",
            "Epoch 96/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.5962\n",
            "Epoch 97/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.4808\n",
            "Epoch 98/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.3565\n",
            "Epoch 99/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.2361\n",
            "Epoch 100/100\n",
            "3233/3233 [==============================] - 33s 10ms/step - loss: 2.1405\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78d8fef0a560>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## generate char sequence\n",
        "\n",
        "start_index = np.random.randint(0,len(X)-1)\n",
        "\n",
        "sequence = X[start_index]\n",
        "print(start_index)\n",
        "char_seq = [int_to_char[inte] for inte in sequence]\n",
        "\n",
        "prediction = ''\n",
        "for i in range(10):\n",
        "\n",
        "    ## reshape sequence\n",
        "    x = np.reshape(sequence, (1, timestep,1))\n",
        "    x = x / float(len(unique_chars))\n",
        "\n",
        "    # predict\n",
        "    y_pred_int = np.argmax(model.predict(x, verbose=0))\n",
        "    char_out = int_to_char[y_pred_int]\n",
        "    prediction += char_out\n",
        "\n",
        "    ## update sequence for next char prediction\n",
        "    sequence.append(y_pred_int)\n",
        "    sequence = sequence[-timestep:]\n",
        "\n",
        "print(f'input string: {\"\".join(char_seq)}')\n",
        "print(f'generated string: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odj0DU68PxpU",
        "outputId": "9612edc2-eb4d-4023-e659-b246ca5d6c16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6727\n",
            "input string: as breath into the winde.would they had stay'd   b\n",
            "generated string: anq. whos \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join([int_to_char[inte] for inte in X[6727+10][-10:]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FZvElr6gWd8H",
        "outputId": "31b1b24c-2098-4725-d46b-a1ff9f286020"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anq. were '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results:\n",
        "\n",
        "### Generate next 10 characters after the below sequence:\n",
        "\n",
        "#### sequence: \"as breath into the winde.would they had stay'd   b\"\n",
        "\n",
        "#### true: \"anq. were\"\n",
        "\n",
        "#### predicted: \"anq. whos\""
      ],
      "metadata": {
        "id": "6oCRS0AExsFm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MDEVTZh4xnrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}